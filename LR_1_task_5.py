# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kXPjeqGyyqKws-UVBVf_t6V94R5BiGNq
"""

import numpy as np
import pandas as pd
from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, roc_auc_score
import matplotlib.pyplot as plt

# Завантаження даних з CSV-файлу
df = pd.read_csv('data_metrics.csv')
print(df.head())

# Встановлення порогу
thresh = 0.5

# Створення стовпців з передбаченнями
df['predicted_RF'] = (df['model_RF'] >= thresh).astype('int')
df['predicted_LR'] = (df['model_LR'] >= thresh).astype('int')
print(df.head())

# Обчислення матриці помилок для моделі Random Forest
conf_matrix_RF = confusion_matrix(df['actual_label'].values, df['predicted_RF'].values)
print("Матриця помилок для моделі Random Forest:\n", conf_matrix_RF)

# Обчислення матриці помилок для моделі Logistic Regression
conf_matrix_LR = confusion_matrix(df['actual_label'].values, df['predicted_LR'].values)
print("Матриця помилок для моделі Logistic Regression:\n", conf_matrix_LR)

# Визначення функцій для обчислення TP, FN, FP та TN
def find_TP_Pysanetskyi(y_true, y_pred):
    # Рахує кількість істинно позитивних (y_true = 1, y_pred = 1)
    return sum((y_true == 1) & (y_pred == 1))

def find_FN_Pysanetskyi(y_true, y_pred):
    # Рахує кількість хибно негативних (y_true = 1, y_pred = 0)
    return sum((y_true == 1) & (y_pred == 0))

def find_FP_Pysanetskyi(y_true, y_pred):
    # Рахує кількість хибно позитивних (y_true = 0, y_pred = 1)
    return sum((y_true == 0) & (y_pred == 1))

def find_TN_Pysanetskyi(y_true, y_pred):
    # Рахує кількість істинно негативних (y_true = 0, y_pred = 0)
    return sum((y_true == 0) & (y_pred == 0))

# Функція для обчислення значень матриці помилок
def find_conf_matrix_values(y_true, y_pred):
    # Обчислює TP, FN, FP, TN
    TP = find_TP_Pysanetskyi(y_true, y_pred)
    FN = find_FN_Pysanetskyi(y_true, y_pred)
    FP = find_FP_Pysanetskyi(y_true, y_pred)
    TN = find_TN_Pysanetskyi(y_true, y_pred)
    return TP, FN, FP, TN

# Функція для створення матриці помилок
def pysanetskyi_confusion_matrix(y_true, y_pred):
    TP, FN, FP, TN = find_conf_matrix_values(y_true, y_pred)
    return np.array([[TN, FP], [FN, TP]])

# Визначення власної функції для обчислення точності
def my_accuracy_score(y_true, y_pred):
    # Обчислює точність, використовуючи формулу
    TP, FN, FP, TN = find_conf_matrix_values(y_true, y_pred)
    return (TP + TN) / (TP + TN + FP + FN)

# Визначення власної функції для обчислення точності (precision)
def my_precision_score(y_true, y_pred):
    # Обчислює точність (precision), використовуючи формулу
    TP, FN, FP, TN = find_conf_matrix_values(y_true, y_pred)
    return TP / (TP + FP)

# Перевірка правильності роботи функції за допомогою assert
assert np.array_equal(pysanetskyi_confusion_matrix(df.actual_label.values, df.predicted_RF.values),
                      confusion_matrix(df.actual_label.values, df.predicted_RF.values)), 'pysanetskyi_confusion_matrix() is not correct for RF'
assert np.array_equal(pysanetskyi_confusion_matrix(df.actual_label.values, df.predicted_LR.values),
                      confusion_matrix(df.actual_label.values, df.predicted_LR.values)), 'pysanetskyi_confusion_matrix() is not correct for LR'

# Використання функцій для підрахунку TP, FN, FP та TN
TP_RF = find_TP_Pysanetskyi(df['actual_label'].values, df['predicted_RF'].values)
FN_RF = find_FN_Pysanetskyi(df['actual_label'].values, df['predicted_RF'].values)
FP_RF = find_FP_Pysanetskyi(df['actual_label'].values, df['predicted_RF'].values)
TN_RF = find_TN_Pysanetskyi(df['actual_label'].values, df['predicted_RF'].values)

print("True Positives (RF):", TP_RF)
print("False Negatives (RF):", FN_RF)
print("False Positives (RF):", FP_RF)
print("True Negatives (RF):", TN_RF)

# Використання accuracy_score для обчислення точності
accuracy_RF = accuracy_score(df.actual_label.values, df.predicted_RF.values)
accuracy_LR = accuracy_score(df.actual_label.values, df.predicted_LR.values)

print("\nТочність для моделі Random Forest:", accuracy_RF)
print("Точність для моделі Logistic Regression:", accuracy_LR)

# Перевірка правильності роботи my_accuracy_score
assert my_accuracy_score(df.actual_label.values, df.predicted_RF.values) == accuracy_score(df.actual_label.values, df.predicted_RF.values), 'my_accuracy_score() failed on RF'
assert my_accuracy_score(df.actual_label.values, df.predicted_LR.values) == accuracy_score(df.actual_label.values, df.predicted_LR.values), 'my_accuracy_score() failed on LR'

# Виведення результатів за допомогою my_accuracy_score
print('Точність для моделі Random Forest (my_accuracy_score): %.3f' % my_accuracy_score(df.actual_label.values, df.predicted_RF.values))
print('Точність для моделі Logistic Regression (my_accuracy_score): %.3f' % my_accuracy_score(df.actual_label.values, df.predicted_LR.values))

# Виведення результатів за допомогою my_precision_score
print('Точність для моделі Random Forest (my_precision_score): %.3f' % my_precision_score(df.actual_label.values, df.predicted_RF.values))
print('Точність для моделі Logistic Regression (my_precision_score): %.3f' % my_precision_score(df.actual_label.values, df.predicted_LR.values))

# Побудова ROC-кривих
fpr_RF, tpr_RF, thresholds_RF = roc_curve(df.actual_label.values, df.model_RF.values)
fpr_LR, tpr_LR, thresholds_LR = roc_curve(df.actual_label.values, df.model_LR.values)

plt.plot(fpr_RF, tpr_RF, 'r-', label='RF')
plt.plot(fpr_LR, tpr_LR, 'b-', label='LR')
plt.plot([0, 1], [0, 1], 'k--', label='random')
plt.plot([0, 0, 1, 1], [0, 1, 1, 1], 'g-', label='perfect')

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-криві для моделей Random Forest та Logistic Regression')
plt.legend()
plt.show()

# Обчислення AUC
auc_RF = roc_auc_score(df.actual_label.values, df.model_RF.values)
auc_LR = roc_auc_score(df.actual_label.values, df.model_LR.values)

print('AUC RF:%.3f' % auc_RF)
print('AUC LR:%.3f' % auc_LR)

# Побудова графіків ROC-кривих
fpr_RF, tpr_RF, thresholds_RF = roc_curve(df.actual_label.values, df.model_RF.values)
fpr_LR, tpr_LR, thresholds_LR = roc_curve(df.actual_label.values, df.model_LR.values)

plt.plot(fpr_RF, tpr_RF, 'r-', label='RF AUC: %.3f' % auc_RF)
plt.plot(fpr_LR, tpr_LR, 'b-', label='LR AUC: %.3f' % auc_LR)
plt.plot([0, 1], [0, 1], 'k--', label='random')
plt.plot([0, 0, 1, 1], [0, 1, 1, 1], 'g-', label='perfect')

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-криві для моделей Random Forest та Logistic Regression')
plt.legend()
plt.show()

"""# Новый раздел"""